# 9-7
调试代码，在vit 的rm文档中，有在虚拟机上详细的配置指导，但是可能自己还看不太懂，明天需要在详细看一看。

从本路径中查找包
```shell
pip install -r requirements.txt
```

安装vit_jax包，在vision_transformer-main的路径下，输入
```
pip install .  #注意后面的小点，要用空格隔开
```

返回上一目录
```
cd ..
```

## 一些常用命令
### Python
#### 1.python 运行
```shell
python main.py   #开始执行 `main.py` 文件 
```
在命令行窗口中输入 `python`，会进入 Python 交互式环境中，可以输入任何 Python 代码，回车后会立刻得到执行结果。输入 `exit()` 并回车可退出 `Python Shell`
#### 2.pip命令
```shell
pip <command> [options]  # 查看 pip 命令的使用方式
pip list                 # 列表列出已安装的包
pip list --outdated：    #列表列出有新版本的第三方库
pip install package      #安装最新的包
pip install package==1.0.1      #安装指定包
pip install -U package   # 升级最新版本
pip install package -i http:mirrors~~~ #下载指定源
pip download package     # 下载包
pip ununstall package    # 卸载
pip show package         # 展示包信息
```

### BASH
#### 1.文件系统
```shell
ls
touch filename
mkdir dirName
mkdir -p dirName
cat filename
less filename
head filename
head -n 20 filename
tail filename
wc filename
mv f1 f2:
cp f1 f2:
rm filename
rm -r foldername
chmod -options filename
```
#### 2.压缩与解压
```shell
zip -r mydata.zip mydata
unzip mydata.zip
unzip mydata.zip -d mydatak
gzip file
gzip -r /dir
gzip -d file.gz
```

# 9-8
详细读rm文档，有何新发现会记录在下面

---
## 安装
提到Python>=3.10
使用GPU时，用以下命令安装JAX和python的依赖项
```shell
pip install -r vit_jax/requirements.txt
```
对于**更新版本的JAX**，请按照此处链接的相应存储库中提供的说明进行操作： https://github.com/google/jax

安装**Flaxformer**,按照链接的现因储存库提供的说明进行操作：
https://github.com/google/flaxformer

## 模型微调（Fine-turning）
可以在感兴趣的数据集上运行下载模型的微调。同时，所有模型都共享相同的命令行界面

比如：在CIFAR10上微调一个ViT-B/16（在imagenet21k上预训练），请执行以下命令（请注意，将b16,cifar10作为参数指定给config，并指示代码直接从GCS存储桶访问模型，而不是首先将其下载到本地目录）：
``` shell
python -m vit_jax.main --workdir=/tmp/vit-$(date +%s) \
    --config=$(pwd)/vit_jax/configs/vit.py:b16,cifar10 \
    --config.pretrained_dir='gs://vit_models/imagenet21k'
```
要在CIFAR10上微调一个Mixer-B/16（在imagenet21k上预训练），请执行以下命令
```shell
python -m vit_jax.main --workdir=/tmp/vit-$(date +%s) \
    --config=$(pwd)/vit_jax/configs/mixer_base16_cifar10.py \
    --config.pretrained_dir='gs://mixer_models/imagenet21k'
```

> [!NOTE] 注意
> 上面两个代码块中一些路径的不同，可以修改其中的一些路径，达到我们想要的训练目的
> 

**"How to train your ViT?..."** 论文中添加了50,000多个检查点，可以使用`configs/augreg.py`配置进行微调。只指定模型名称（configs/model.py中的config.name值）时，会选择最佳的i21k检查点（通过上游验证准确性选择的“推荐”检查点，参见论文第4.5节）。要确定要使用的模型，请查看论文中的图3。还可以选择不同的检查点（参见Colab vit_jax_augreg.ipynb），然后指定与`gs://vit_models/augreg`目录中没有`.npz`的文件名对应的值
```shell
python -m vit_jax.main --workdir=/tmp/vit-$(date +%s) \
    --config=$(pwd)/vit_jax/configs/augreg.py:R_Ti_16 \
    --config.dataset=oxford_iiit_pet \
    --config.base_lr=0.01
```


代码会**自动**下载CIFAR-10和CIFAR-100数据集，其他公共或自定义数据集可以轻松集成，使用tensorflow数据集库 https://github.com/tensorflow/datasets/ 。注意，需要更新`vit_jax/input_pipeline.py`以指定有关任何添加的数据集的一些参数

代码会使用所有可用的GPU/TPU进行微调
要查看所有可用标志的详细列表，请运行`python3 -m vit_jax.train --help`
## 内存注意事项

- 不同的模型需要不同数量的内存。可用内存还取决于加速器配置（类型和数量）。如果遇到内存不足的错误，可以增加 `--config.accum_steps=8`的值，或者减小`--config.batch=512`（并相应减小`--config.base_lr`）。

- 主机在内存中保留一个洗牌缓冲区。如果遇到主机内存不足的情况（与加速器内存不足相反），可以减小默认值`--config.shuffle_buffer=50000`

## 可用的ViT model
作者在GCS中提供了各种ViT模型，可以用以下命令下载模型：
```shell
wget https://storage.googleapis.com/vit_models/imagenet21k/ViT-B_16.npz
```
模型文件名（不带.npz扩展名），对应`vit_jax/configs/models.py`中的`config.model_name`
- 在ImageNet-21k上进行预训练的模型- https://console.cloud.google.com/storage/browser/vit_models/imagenet21k/
- 在ImageNet-21k上进行预训练，并在ImageNet上进行微调的模型- https://console.cloud.google.com/storage/browser/vit_models/imagenet21k+imagenet2012/
- 在ImageNet-21k上进行预训练的模型，并应用不同程度的AugReg。性能提升 - https://console.cloud.google.com/storage/browser/vit_models/augreg/
- 在ImageNet上使用SAM进行预训练的模型 - https://console.cloud.google.com/storage/browser/vit_models/sam/
- 在ImageNet上使用GSAM进行预训练的模型 - https://console.cloud.google.com/storage/browser/vit_models/gsam/
SAM 和 GSAM 好像用不到，但是也先写下来了，原文中用的是shell命令，举第一个例子：`gs://vit_models/imagenet21k` ，只选这一段进行获取即可。

### 检查点
作者推荐使用通过AugReg进行预训练的检查点，这些检查点具有最佳的预训练指标，太多了，看原文吧😭

## 好消息！！！
原始ViT论文(https://arxiv.org/abs/2010.11929) 的结果已经使用来自`gs://vit_models/imagenet21k`的模型进行了复制:
也就是说，我们去下载这个模型进行微调就行！！！（应该是的吧

文中还提到了 **MLP-Mixer**和**LiT mode**，感觉没关系，略过

## 设置VM
**好像在矩池云上没办法用这个进行按照，只能用conda**
然后像往常一样获取存储库和安装依赖项:
```shell
git clone --depth=1 --branch=master https://github.com/google-research/vision_transformer
cd vision_transformer

# optional: install virtualenv
pip3 install virtualenv
python3 -m virtualenv env
. env/bin/activate
```
如果是连接到一个带有gpu的虚拟机，使用以下命令安装JAX和其他依赖项:
```shell
pip install -r vit_jax/requirements.txt
```


---
**好像，貌似**复现论文，只想要我把整个模型中中，models_vit跑起来就行了，该模型中的流程与论文中的流程一一对应
![[Pasted image 20240908111208.png]]
![[Pasted image 20240908111255.png]]